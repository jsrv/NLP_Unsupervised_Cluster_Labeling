{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brigham Young University\n",
    "    Bailey Smith\n",
    "    Juan S. Rodriguez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Abstract\n",
    "TED talks have become a standard on how to deliver informational talks. All of these talks are presented in a digital format online for public viweing. By using the transcripts and website data for all TED talks given up to September 2017 +++. Each video in the website is provided with suggested similar videos and informative topic-tags on them. We present an improvement in the suggested videos, and we consolidate a base on tags that are more useful by using bisecting k-means and LDA-GS respectively.\n",
    "\n",
    "## TED Talks\n",
    "Since 1984, TED has become an iconic conference in which experts of the world in different fields present their ideas and analysis in the fields of technology, entertainment and design (T.E.D.). Since 2006, the conference platform decided to make every talk public and free by publishing them on their website. Given its history and prestige, TED talks have become a standard for quality when it comes to delivering an informational talk to an audience.\n",
    "\n",
    "## Motivation\n",
    "We wish to create a labeling and clustering process to process documents, videos, or talks based solely on their transcript. Our secondary objective if for this process to have minimun to none human intervention. We will be using the transcripts on all the TED talks that have been published up to September 2017 (roughly 2400).\n",
    "\n",
    "An automatic and human-less classification method would allow better suggestions to the online audience, would provide an **unbiased-human classification**, and would be generalizable to other fields and problems. This sort of classification method would give the tools for a machine to sort through thousands of legal documents, health documents, speech transcript, or even books, and allow the scholar or reader to approach them seamlessly. \n",
    "\n",
    "## Algorithm Approach:\n",
    "The process will be divided fundamentally into two different parts.\n",
    "\n",
    "The first part will be the labeling process. The labelling process will be split into three different steps. The first step will be to apply a Latent Dirichlet Allocation (LDA) using a Gibbs Sampling technique in order to find the prevalent topics in the whole corpus of TED talks. This will give us a list of words for each topic which describes the topic. The second labeling step is to find a tagging label for each topic. Given the list of words assigned to each topic, we implement and algorithm to assign a macro concept that encapsulate all the words for each topic. For example, our LDA may have as an output the following list: `['government', 'party', 'elections', 'voting', 'candidate']` \n",
    "Step two will label this as `Politics`. Step three is applying these topic labels to the different clusters that will be provided by part two.\n",
    "\n",
    "The second part will be a two-fold. First, we will use a bisecting K-Means algorithm in order to determine what the main clusters in the text are. Second, we will use a cosine similarity system to find related documents.\n",
    "\n",
    "1. Labeling\n",
    "    2. LDA - Prevalent Topics\n",
    "    2. Wiki, Glove - Label the topics\n",
    "    2.  - Label the clusters\n",
    "1. Clustering\n",
    "    2. Bisecting KMeans - Main Clusters\n",
    "    2. Cosine Similarity - Related Talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = pd.DataFrame([['title:','str', 'The title of the talk'],\n",
    "['description:','str', 'A blurb of what the talk is about'],\n",
    "['main_speaker:','str', 'The first named speaker of the talk'],\n",
    "['speaker_occ:','str', 'The occupation of the main speaker'],\n",
    "['num_speaker:','int', 'The number of speakers in the talk'],\n",
    "['duration:','int', 'The duration of the talk in seconds'],\n",
    "['film_date:','int', 'The date of filming Unix timestamp'],\n",
    "['published_date:','int', 'The online publication Unix timestamp'],\n",
    "['comments:','int', 'The number of comments made on the talk'],\n",
    "['languages:','int', 'Number of languages available for talk'],\n",
    "['ratings:','dict', 'The various ratings given to the talk'],\n",
    "['url:','url', 'The URL of the talk'],\n",
    "['views:','int', 'The number of views on the talk'],\n",
    "['related_talks:','dict', 'List of dict of 6 related talks'],\n",
    "['tags:','list', 'The themes associated with the talk']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} &                0 &     1 &                                        2 \\\\\n",
      "\\midrule\n",
      "0  &           title: &   str &                    The title of the talk \\\\\n",
      "1  &     description: &   str &        A blurb of what the talk is about \\\\\n",
      "2  &    main\\_speaker: &   str &      The first named speaker of the talk \\\\\n",
      "3  &     speaker\\_occ: &   str &       The occupation of the main speaker \\\\\n",
      "4  &     num\\_speaker: &   int &       The number of speakers in the talk \\\\\n",
      "5  &        duration: &   int &      The duration of the talk in seconds \\\\\n",
      "6  &       film\\_date: &   int &       The date of filming Unix timestamp \\\\\n",
      "7  &  published\\_date: &   int &    The online publication Unix timestamp \\\\\n",
      "8  &        comments: &   int &  The number of comments made on the talk \\\\\n",
      "9  &       languages: &   int &   Number of languages available for talk \\\\\n",
      "10 &         ratings: &  dict &    The various ratings given to the talk \\\\\n",
      "11 &             url: &   url &                      The URL of the talk \\\\\n",
      "12 &           views: &   int &          The number of views on the talk \\\\\n",
      "13 &   related\\_talks: &  dict &          List of dict of 6 related talks \\\\\n",
      "14 &            tags: &  list &      The themes associated with the talk \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(variables.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
