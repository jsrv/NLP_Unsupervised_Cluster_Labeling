{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "Proper labeling allows users to understand the content of available documents such as scientific papers, movies, books, music, legal documents, and any medium from which text can be extracted. Labeling is an inherently biased and time-expensive problem, given that it is restricted by the labels that a human can provide, and because it requires studying the complete document and having field knowledge to provide a proper label.  We suggest an innovative document labeling method that works completely unsupervised. This implies no human priors to suggest labeling, and thus no human selection bias. We demonstrate the usefulness of this algorithm by labeling TED talks based solely on their transcripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Motivation\n",
    "We wish to create a labeling and clustering process to process documents, videos, or talks based solely on their transcript. Our secondary objective if for this process to have minimun to none human intervention. We will be using the transcripts on all the TED talks that have been published up to September 2017 (roughly 2400).\n",
    "\n",
    "An automatic and human-less classification method would allow better suggestions to the online audience, would provide an **unbiased-human classification**, and would be generalizable to other fields and problems. This sort of classification method would give the tools for a machine to sort through thousands of legal documents, health documents, speech transcript, or even books, and allow the scholar or reader to approach them seamlessly by following their labels.\n",
    "\n",
    "We have found several research papers that have attempted to solve this problem. We suggest that our approach can propose a better genre or topic labeling for large document sets (i.e.  hundreds of books, legal documents, or movies) or give a human-like description of a unique document (i.e. a book). The reson for this is that most labeling techniques rely on in-document information, which can be very limited, or a trained or pre-determined labeling set. Our approach does not depend on the limitations of within-document content nor human decided labels to tag the data.\n",
    "\n",
    "## TED Talks\n",
    "Since 1984, TED has become an iconic conference in which experts of the world in different fields present their ideas and analysis in the fields of technology, entertainment and design (T.E.D.). Since 2006, the conference platform decided to make every talk public and free by publishing them on their website. Given its history and prestige, TED talks have become a standard for quality when it comes to delivering an informational talk to an audience. We will use the transcripts that come from their talks to suggest individual talk labeling and cluster labeling. We will compare our labels with those given by the organization itself.\n",
    "\n",
    "# Data\n",
    "## Description\n",
    "TED talks have very diverse content in their talks. For this reason we would like to provide some insight in what the data looks like. The most common TED speaker occupation is \"Writer\" with 45 occurrences, followed by \"Designer\" with a total of 34 occurrences. The total number of occupations among speakers is 1458. The average talk is 13.7 minutes long, with the shortest being 2.25 minutes and the longest being about 1.5 hours, which was given by the author of \"The Hitchhiker's Guide to the Galaxy\". The average TED talk has been translated to 27 languages, and there are 86 talks that have no assigned language. These talks will not be used as their is no transcript available for them, given that they are mainly musical presentations. The average number of views per talk is 1.6 million and the talk with highest number of views has been seen almost 50 million times and it's called \"Do schools kill creativity?\".\n",
    "\n",
    "With regards to the video tags, TED gives each video a number of possible tags to link a talk with different topics. The average video has 7.56 tags, with some videos having over 30 tags and some having just one. The other important variable that will be useful for us to observe is the related talks. Every video is given a connection to 6 other videos that are suggested for the viewer to watch. We suggest to improve these two metrics, having specific tags that might be more useful for the viewer, and testing if there is any link in the related talks with the number of views the talks have.\n",
    "\n",
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TEX\n",
    "\\begin{tabular}{llll}\n",
    "\\toprule\n",
    "Variable &                Type &     Description  \\\\\n",
    "\\midrule\n",
    "title: &         str &                    The title of the talk \\\\\n",
    "description: &         str &        A blurb of what the talk is about \\\\\n",
    "main\\_speaker: &         str &      The first named speaker of the talk \\\\\n",
    "speaker\\_occ: &         str &       The occupation of the main speaker \\\\\n",
    "duration: &         int &      The duration of the talk in seconds \\\\\n",
    "url: &         url &                      The URL of the talk \\\\\n",
    "\\_talks: &        dict &          List of dict of 6 related talks \\\\\n",
    "tags: &        list &      The themes associated with the talk \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcript Dataset\n",
    "The transcript dataset contains the transcripts for 2467 TED talks. In this database we found three duplicates. We decided to analyze only the talks that are found on both databases in order to have homogeneous data. The 86 talks for which there is no transcript data are the music ones we had referred to before. We discarded any dupiclates.\n",
    "\n",
    "#### Source:\n",
    "The data has been scraped from the official TED Website and is available under\n",
    "the Creative Commons License. It was retrieved from the Kaggle featured data sets in October 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "## Algorithm Approach:\n",
    "The process will be divided fundamentally into two different parts.\n",
    "\n",
    "The first part will be the labeling process. The labelling process will be split into three different steps. The first step will be to apply a Latent Dirichlet Allocation (LDA) using a Gibbs Sampling technique in order to find the prevalent topics in the whole corpus of TED talks. This will give us a list of words for each topic which describes the topic. The second labeling step is to find a tagging label for each topic. Given the list of words assigned to each topic, we implement and algorithm to assign a macro concept that encapsulate all the words for each topic. For example, our LDA may have as an output the following list: `['government', 'party', 'elections', 'voting', 'candidate']`. Step two will label this list of topics under the concept `Politics`. Step three is applying these topic labels to the different clusters that will be provided by part two.\n",
    "\n",
    "The second part will be a two-fold. First, we will use a bisecting K-Means algorithm in order to determine what the main clusters in the text are. Second, we will use a cosine similarity system to find related documents.\n",
    "\n",
    "1. Creating Labels\n",
    "    2. LDA - Prevalent Topics\n",
    "    2. Wiki, Glove - Label the topics\n",
    "    2. Labeling\n",
    "        - Cluster Labeling\n",
    "        \n",
    "            *-OR-*\n",
    "        - Individual Topic Labeling\n",
    "\n",
    "\n",
    "1. Clustering\n",
    "    2. Bisecting KMeans - Main Clusters\n",
    "        3. Count Vectorizer\n",
    "        3. sklearn.feature_extraction.text.CountVectorizer\n",
    "        \n",
    "    2. Cosine Similarity - Related Talks\n",
    "\n",
    "### LDA with Gibbs Sampling Topic selection\n",
    "\n",
    "### Wiki and GloVe Topic Selection\n",
    "\n",
    "Given all the readily available information that can be found online, we used the GloVe dataset provided by +++ and the Wikipedia API to extra readily available public knowledge data and \n",
    "### Cluster Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "After applying the algorithm to the TED talk transcripts dataset, we got the following results. After applying a 7 cluster approach we can see the following:\n",
    "    (visualize similar talks from the clusters)\n",
    "    \n",
    "Each cluster was labeled as follows:\n",
    "    (Show the labels and some titles found in the clusters\n",
    "    \n",
    "The suggestions found on the website do this:\n",
    "    (Compare a sample of ten talks labeled by the algorithm vs by TED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "We"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "Dictionary API\n",
    "Macro Concept Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
